{
  "init_scale": 0.05,
  "learning_rate": 1.0,
  "max_grad_norm": 5,
  "num_layers": 2,
  "num_steps": 35,
  "emb_size": 650,
  "state_size": 650,
  "lr_decay_wait": 6,
  "max_epochs": 39,
  "keep_prob": 0.5,
  "emb_keep_prob": 0.5,
  "lr_decay_factor": 0.8,
  "batch_size": 20,
  "l2_loss_weight": 0.0,
  "vocab_size": 10000
}
